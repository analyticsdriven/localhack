{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Houston Local Hack Day at University fo Houston PGH 232\n",
    "### Team: Anooj Shah, Lucas Atayde, Kari Burt, Jennifer Cai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Motivation\n",
    "\n",
    "The team decided to use sentiment analysis on user input. We were aware of what sentiment analysis was, but we are new to NPL and our first attempt at implementing in python. I went and looked up more information about NLP from https://en.wikipedia.org/wiki/Sentiment_analysis Some things I didn't expect were \"Emoji Sentiment Ranking\" which makes sense but I would not have thought of it without reading about it\n",
    "\n",
    "The resources we used include the following\n",
    "- https://en.wikipedia.org/wiki/Sentiment_analysis\n",
    "- https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart\n",
    "- https://planspace.org/20150607-textblob_sentiment/\n",
    "- https://www.lexalytics.com/technology/sentiment\n",
    "\n",
    "### Early Challenges and Binder\n",
    "\n",
    "Our team is novice to collaborating via Github. We had some initial challenge sharing code. As always first time setup is a challenge and one of our concerns was reproducability / deployment. To compensate I tried to deploy using binder for the first time. My strategy to share is to fork our main repo, https://github.com/anooj-shah/localhack, and then submit pull requests. This notebook was uploaded to binder for easier integration.\n",
    "\n",
    "### The Project and the Plan\n",
    "\n",
    "Our team wanted to develop a mental health application. In this step I am reading a csv of timestamps and text as a list. This information is being passed through TextBlob to run sentiment analysis. The output is written to a CSV for processing by data visualization team.\n",
    "\n",
    "**Meet the Team**\n",
    "- **Lucas** has been building a Python app using the Twilio API\n",
    "- **Jennifer** has been working on using TextBlob to do sentiment analysis and write to CSV\n",
    "- **Anooj** is managing our Github and taking care of the visualizations\n",
    "- **Kari** is putting it all together with her web development skills\n",
    "\n",
    "#### A quick explanation of TextBlob from https://planspace.org/20150607-textblob_sentiment/\n",
    "\n",
    "Each word in the lexicon has scores for:\n",
    " 1. polarity: negative vs. positive    (-1.0 => +1.0)\n",
    " 2. subjectivity: objective vs. subjective (+0.0 => +1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with Python Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Import and Read from File\n",
    "\n",
    "In the planning stages, we decided that Lucas would generate a CSV of two columns, time stamp and user input string. I generated a dummy_input.csv for testing. In this step we read the CSV input and parse it to the TextBlob library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('16', '‚ÄúThis incredible artist had ALS and had been lying motionless in bed for 7 years‚Ä¶ we were determined to help him draw again.‚Äù Mick Ebeling and Not Impossible Labs tackle the impossible every day. What should they tackle next?\\n'), ('14', \"A month ago I applied for a small loan at Wells Fargo for the 1st time ever to consolidate some small bills. They denied the loan. I went to a local Credit Union and they gave me the loan. Today I signed up for a checking/savings account at that Credit Union and canceled my accounts with Wells Fargo. Couldn't be happier to stop doing business with a crooked ass corporation.\\n\"), ('8', '\"My wife and I lived on the west coast and I had to leave my job (internship expired). We were running shorter and shorter on cash and were forced to break out our credit card to stay afloat for a while. We used it for rent a few times (big no-no) and for lots of other things. We were both miserable out there so we moved to the midwest in June of 2018. By the time the move was over'), ('14', '\"Khashoggi'), ('15', '\"Parents who force unremorseful kids to apologize to others before they‚Äôre truly sorry may do more harm than good'), ('19', '\"I\\'ve heard from countless people that Python is \"\"slower\"\" than languages like C++'), ('22', '\"I‚Äôve tried applying it daily on my lashes for 2 weeks and noticed such DRAMATIC difference. My lashes were much'), ('20', \"It took our whole team months to plan and prepare this big initiative to promote our platform. And it took even longer to get our platform to the point where it delivered real value for people and to be ready for big promotion. Please support and share if it's something that might interest you or someone you know.\\n\"), ('3', '\"Hey guys'), ('6', '\"\"\"Jeb'), ('12', '\"I have a list of player point projections')]\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "#Input_list is the data frame of all the available input\n",
    "\n",
    "input_list = []\n",
    "\n",
    "#Open the CSV of input\n",
    "\n",
    "infile = open(\"dummy_input.csv\", 'r')\n",
    "\n",
    "#Read every line and place each into the input_list as a tuple\n",
    "\n",
    "for line in infile:\n",
    "    data = line.split(',')\n",
    "    time = data[0]\n",
    "    user_input = data[1]\n",
    "    input_list.append((time, user_input))\n",
    "infile.close()\n",
    "\n",
    "print(input_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Analyze the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06000000000000001\n",
      "-0.34166666666666673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextBlob(\"La amenaza titular de The Blob siempre me ha parecido la pel√≠cula definitiva.\n",
       "Monstruo: una masa con forma de ameba insaciablemente hambrienta capaz de penetrar\n",
       "virtualmente cualquier salvaguardia, capaz de - como un doctor condenado de forma escalofriante\n",
       "Lo describe - \"asimilando carne al contacto.\n",
       "Las malditas comparaciones con la gelatina se condenan, es un concepto con el m√°s\n",
       "devastadora de posibles consecuencias, no a diferencia del escenario goo gris\n",
       "Propuesto por te√≥ricos tecnol√≥gicos temerosos de\n",
       "La inteligencia artificial corre desenfrenada.\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "text = '''\n",
    "The titular threat of The Blob has always struck me as the ultimate movie\n",
    "monster: an insatiably hungry, amoeba-like mass able to penetrate\n",
    "virtually any safeguard, capable of--as a doomed doctor chillingly\n",
    "describes it--\"assimilating flesh on contact.\n",
    "Snide comparisons to gelatin be damned, it's a concept with the most\n",
    "devastating of potential consequences, not unlike the grey goo scenario\n",
    "proposed by technological theorists fearful of\n",
    "artificial intelligence run rampant.\n",
    "'''\n",
    "\n",
    "blob = TextBlob(text)\n",
    "blob.tags           # [('The', 'DT'), ('titular', 'JJ'),\n",
    "                    #  ('threat', 'NN'), ('of', 'IN'), ...]\n",
    "\n",
    "blob.noun_phrases   # WordList(['titular threat', 'blob',\n",
    "                    #            'ultimate movie monster',\n",
    "                    #            'amoeba-like mass', ...])\n",
    "\n",
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment.polarity)\n",
    "# 0.060\n",
    "# -0.341\n",
    "\n",
    "blob.translate(to=\"es\")  # 'La amenaza titular de The Blob...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things we learned\n",
    "\n",
    "- **Lucas** has evolved into a GitHub God\n",
    "- **Jennifer** introduced the team to Jupyter Notebooks, but she was new to deploying on Binder\n",
    "\n",
    "We all learned a little bit about teamwork üòÑ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
